{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_feat_imp(ls_dicts):\n",
    "    dict_agg_imp = dict()\n",
    "    dict_agg_freq = dict()\n",
    "    for dict_feat_imp in ls_dicts:\n",
    "        for i in dict_feat_imp:\n",
    "            if i in dict_agg_imp:\n",
    "                dict_agg_imp[i] = dict_agg_imp[i] + dict_feat_imp[i]\n",
    "            else:\n",
    "                dict_agg_imp[i] = dict_feat_imp[i]\n",
    "\n",
    "            if i in dict_agg_freq:\n",
    "                dict_agg_freq[i] = dict_agg_freq[i] + 1\n",
    "            else:\n",
    "                dict_agg_freq[i] = 1\n",
    "\n",
    "    for j in dict_agg_imp:\n",
    "        dict_agg_imp[j] = dict_agg_imp[j] / dict_agg_freq[j]\n",
    "\n",
    "    return dict_agg_imp, dict_agg_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(ls_str):\n",
    "    dict_output = dict()\n",
    "    ls_str = ls_str[1: len(ls_str) - 1]\n",
    "    str_splits = ls_str.split(',')\n",
    "    for str_split in str_splits:\n",
    "        feat_split = str_split.split(':')\n",
    "        feat_name = eval(feat_split[0]).lstrip()\n",
    "        feat_imp = float(feat_split[1])\n",
    "        dict_output[feat_name] = feat_imp\n",
    "        \n",
    "    return dict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comm_feat(ls_xgb_dict, ls_rf_dict):\n",
    "    dict_imp_xgb, dict_freq_xgb = agg_feat_imp(ls_xgb_dict)\n",
    "    dict_imp_rf, dict_freq_rf = agg_feat_imp(ls_rf_dict)\n",
    "    \n",
    "    ls_xgb_imp = list()\n",
    "    for feat_name in dict_imp_xgb:\n",
    "        ls_row = [feat_name, dict_imp_xgb[feat_name]]\n",
    "        ls_xgb_imp.append(ls_row)\n",
    "        \n",
    "    ls_xgb_freq = list()\n",
    "    for feat_name in dict_freq_xgb:\n",
    "        ls_row = [feat_name, dict_freq_xgb[feat_name]]\n",
    "        ls_xgb_freq.append(ls_row)\n",
    "    \n",
    "    ls_rf_imp = list()\n",
    "    for feat_name in dict_imp_rf:\n",
    "        ls_row = [feat_name, dict_imp_rf[feat_name]]\n",
    "        ls_rf_imp.append(ls_row)\n",
    "\n",
    "    ls_rf_freq = list()\n",
    "    for feat_name in dict_freq_rf:\n",
    "        ls_row = [feat_name, dict_freq_rf[feat_name]]\n",
    "        ls_rf_freq.append(ls_row)\n",
    "        \n",
    "    df_imp_xgb = pd.DataFrame(ls_xgb_imp, columns = ['Feature', 'Importance'])\n",
    "    df_freq_xgb = pd.DataFrame(ls_xgb_freq, columns = ['Feature', 'Frequency'])\n",
    "    df_imp_rf = pd.DataFrame(ls_rf_imp, columns = ['Feature', 'Importance'])\n",
    "    df_freq_rf = pd.DataFrame(ls_rf_freq, columns = ['Feature', 'Frequency'])\n",
    "    \n",
    "    mean_freq_xgb = np.median(df_freq_xgb['Frequency'].tolist())\n",
    "    mean_imp_xgb = np.median(df_imp_xgb['Importance'].tolist())\n",
    "    mean_freq_rf = np.median(df_freq_rf['Frequency'].tolist())\n",
    "    mean_imp_rf = np.median(df_imp_rf['Importance'].tolist())\n",
    "\n",
    "    df_freq_sub_xgb = df_freq_xgb[df_freq_xgb['Frequency'] >= mean_freq_xgb]\n",
    "    df_imp_sub_xgb = df_imp_xgb[df_imp_xgb['Importance'] >= mean_imp_xgb]\n",
    "    df_freq_sub_rf = df_freq_rf[df_freq_rf['Frequency'] >= mean_freq_rf]\n",
    "    df_imp_sub_rf = df_imp_rf[df_imp_rf['Importance'] >= mean_imp_rf]\n",
    "    \n",
    "    df_sub_xgb = pd.merge(df_freq_sub_xgb, df_imp_sub_xgb, on='Feature')\n",
    "    df_sub_xgb.columns = ['Feature', 'Frequency_XGB', 'Importance_XGB']\n",
    "    df_sub_rf = pd.merge(df_freq_sub_rf, df_imp_sub_rf, on='Feature')\n",
    "    df_sub_rf.columns = ['Feature', 'Frequency_RF', 'Importance_RF']\n",
    "    \n",
    "    df_feat_agg = pd.merge(df_sub_xgb, df_sub_rf, on='Feature')\n",
    "    ls_imp_avg = list()\n",
    "    for i in range(len(df_feat_agg)):\n",
    "        imp_xgb = df_feat_agg.loc[i, 'Importance_XGB']\n",
    "        imp_rf = df_feat_agg.loc[i, 'Importance_RF']\n",
    "        ls_imp_avg.append(np.mean([imp_xgb, imp_rf]))\n",
    "        \n",
    "    df_feat_agg['Ranking Score'] = ls_imp_avg\n",
    "    df_feat_agg_sort = df_feat_agg.sort_values(by='Ranking Score', ascending=False)\n",
    "    df_feat_agg_sort.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_feat_agg_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_feat(ls_keep_feat, pers, df, df_corr):\n",
    "    ls_del_index = list()\n",
    "    ls_corr = list()\n",
    "    for i in range(len(df)):\n",
    "        feat = df.loc[i, 'Feature']\n",
    "        if feat not in ls_keep_feat:\n",
    "            ls_del_index.append(i)\n",
    "        else:\n",
    "            ls_corr.append(df_corr.loc[pers, feat])\n",
    "            \n",
    "            \n",
    "    df_keep = df.drop(ls_del_index, axis = 0)\n",
    "    df_keep.reset_index(drop = True, inplace = True)\n",
    "    df_keep['Corr'] = ls_corr\n",
    "    \n",
    "    return df_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_abbr(df_def, df):\n",
    "    for i in range(len(df)):\n",
    "        feat = df.loc[i, 'Feature']\n",
    "        df_part = df_def[df_def['Feature'] == feat]\n",
    "        feat_abbr = df_part['Abbreviation'].tolist()[0]\n",
    "        df.loc[i, 'Feature'] = feat_abbr\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/ry4jr/Library/Mobile Documents/com~apple~CloudDocs/AAPEX/results')\n",
    "# The definition and abbrevation of features\n",
    "df_feat_defi = pd.read_csv('feat_def.csv')\n",
    "df_ml_input = pd.read_csv('ml_input.csv', index_col = 0)\n",
    "df_ml_input['neoNeuroticism'] = 4 - np.array(df_ml_input['neoNeuroticism'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_names = ['catAntagonism', 'catDetachment', 'catDisinhibition', 'catNegativeAffectivity', 'catPsychoticism', 'neoAgreeableness', 'neoExtraversion', 'neoConscientiousness', 'neoNeuroticism', 'neoOpenness']\n",
    "pers_names_output = ['Antagonism', 'Detachment', 'Disinhibition', 'Negative Affectivity', 'Psychoticism', 'Agreeableness', 'Extraversion', 'Conscientiousness', 'Emotional Stability', 'Openness']\n",
    "df_corr = df_ml_input.corr()\n",
    "df_score_corr = pd.DataFrame(index = pers_names_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df_comm_feat = list()\n",
    "for pers_name in pers_names:\n",
    "    os.chdir('/Users/ry4jr/Library/Mobile Documents/com~apple~CloudDocs/AAPEX/results/xgb_results/')\n",
    "    df_xgb_feat = pd.read_csv('xgb_' + pers_name + '_feats_raw.csv')\n",
    "    ls_xgb_dict = list()\n",
    "    for i in range(len(df_xgb_feat)):\n",
    "        ls_xgb_dict.append(to_dict(df_xgb_feat.loc[i, 'Feats']))\n",
    "    \n",
    "    dict_imp_xgb, dict_freq_xgb = agg_feat_imp(ls_xgb_dict)\n",
    "    os.chdir('/Users/ry4jr/Library/Mobile Documents/com~apple~CloudDocs/AAPEX/results/rf_results/')\n",
    "    df_rf_feat = pd.read_csv('rf_' + pers_name + '_feats_raw.csv')\n",
    "    ls_rf_dict = list()\n",
    "    for i in range(len(df_rf_feat)):\n",
    "        ls_rf_dict.append(to_dict(df_rf_feat.loc[i, 'Feats']))\n",
    "        \n",
    "    \n",
    "    df_comm_feat = comm_feat(ls_xgb_dict, ls_rf_dict)\n",
    "    \n",
    "    ls_df_comm_feat.append(df_comm_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_all_feat_imp = list()\n",
    "for i in range(len(df_feat_defi)):\n",
    "    feat_name = df_feat_defi.loc[i, 'Feature']\n",
    "    for df in ls_df_comm_feat:\n",
    "        if feat_name in df['Feature'].tolist():\n",
    "            ls_all_feat_imp.append(df[df['Feature'] == feat_name]['Ranking Score'].iloc[0])\n",
    "\n",
    "norm_min = np.min(ls_all_feat_imp)\n",
    "norm_max = np.max(ls_all_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_all_feat_imp = list()\n",
    "for i in range(len(df_feat_defi)):\n",
    "    ls_col_feat_rank = list()\n",
    "    ls_col_feat_corr = list()\n",
    "    feat_abbr = df_feat_defi.loc[i, 'Abbreviation']\n",
    "    feat_name = df_feat_defi.loc[i, 'Feature']\n",
    "    for i, df in enumerate(ls_df_comm_feat):\n",
    "        if feat_name in df['Feature'].tolist():\n",
    "            rank_score = df[df['Feature'] == feat_name]['Ranking Score'].iloc[0]\n",
    "            ls_col_feat_rank.append(round((rank_score-norm_min)/(norm_max-norm_min),2))\n",
    "            ls_col_feat_corr.append(round(df_corr.loc[feat_name, pers_names[i]],2))\n",
    "#             rank_score_cell = round((rank_score-norm_min)/(norm_max-norm_min),2)\n",
    "#             if rank_score_cell == 0:\n",
    "#                 ls_col_feat_rank.append(np.nan)\n",
    "#                 ls_col_feat_corr.append(np.nan)\n",
    "#             else:\n",
    "#                 ls_col_feat_rank.append(round((rank_score-norm_min)/(norm_max-norm_min),2))\n",
    "#                 ls_col_feat_corr.append(round(df_corr.loc[feat_name, pers_names[i]],2))\n",
    "        else:\n",
    "            ls_col_feat_rank.append(np.nan)\n",
    "            ls_col_feat_corr.append(np.nan)            \n",
    "            \n",
    "    df_score_corr[feat_abbr + '(Rank)'] = ls_col_feat_rank\n",
    "    df_score_corr[feat_abbr + '(Corr)'] = ls_col_feat_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/ry4jr/Library/Mobile Documents/com~apple~CloudDocs/AAPEX/results/heatmap')\n",
    "df_score_corr.to_csv('feat_rank_corr_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/ry4jr/Library/Mobile Documents/com~apple~CloudDocs/AAPEX/results/heatmap')\n",
    "# Old represents day-level modeling, and new represents person-level modeling\n",
    "df_score_old = pd.read_csv('feat_rank_corr_old.csv', index_col = 0)\n",
    "df_score_new = pd.read_csv('feat_rank_corr_new.csv', index_col = 0)\n",
    "df_feat = pd.read_csv('feat_def.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign the abbrevation to the new results (person-level modeling)\n",
    "dict_feat_new = {'HR1':'HR4',\n",
    "                 'HR2':'HR2',\n",
    "                 'HR3':'HR5',\n",
    "                 'SL1':'SL4',\n",
    "                 'SL2':'SL5',\n",
    "                 'SL3':'SL6',\n",
    "                 'SL4':'SL7',\n",
    "                 'SL5':'SL8',\n",
    "                 'SL6':'SL9',\n",
    "                 'SL7':'SL10',\n",
    "                 'ST1':'ST1',\n",
    "                 'ST2':'ST3',\n",
    "                 'ST3':'ST4',\n",
    "                 'Bat1':'Bat3',\n",
    "                 'Bat2':'Bat2',\n",
    "                 'BL1':'BL1',\n",
    "                 'Call1':'Call1',\n",
    "                 'Call2':'Call3',\n",
    "                 'Call3':'Call4',\n",
    "                 'Call4':'Call5',\n",
    "                 'Call5':'Call6',\n",
    "                 'Call6':'Call7',\n",
    "                 'Call7':'Call8',\n",
    "                 'Call8':'Call9',\n",
    "                 'Aud1':'Aud4',\n",
    "                 'Aud2':'Aud5',\n",
    "                 'Aud3':'Aud6',\n",
    "                 'Loc1':'Loc7',\n",
    "                 'Loc2':'Loc8',\n",
    "                 'SR1':'SR1',\n",
    "                 'SR2':'SR2',\n",
    "                 'SR3':'SR3',\n",
    "                 'SR4':'SR4',\n",
    "                 'Wifi1':'Wifi1',\n",
    "                 'Wifi2':'Wifi2'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_new = list()\n",
    "for col_name in df_score_new.columns.tolist():\n",
    "    feat_name = col_name.split('(')[0]\n",
    "    categ = col_name.split('(')[1][0:4]\n",
    "    col_name_new.append(dict_feat_new[feat_name] + '(' + categ + ')')\n",
    "\n",
    "df_score_new.columns = col_name_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = df_feat.index.tolist()\n",
    "ls_comm_cols = list()\n",
    "for i in feat_names:\n",
    "    ls_comm_cols.append(i + '(Rank)')\n",
    "    ls_comm_cols.append(i + '(Corr)')\n",
    "for i in ls_comm_cols:\n",
    "    if i not in df_score_old.columns.tolist():\n",
    "        df_score_old[i] = [np.nan] * 10\n",
    "    if i not in df_score_new.columns.tolist():\n",
    "        df_score_new[i] = [np.nan] * 10\n",
    "df_score_old = df_score_old[ls_comm_cols]\n",
    "df_score_new = df_score_new[ls_comm_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df_score_old.columns.tolist()\n",
    "pers_names = df_score_old.index.tolist()\n",
    "feat_names = list()\n",
    "for col_name in col_names:\n",
    "    feat_name = col_name.split('(')[0]\n",
    "    if feat_name not in feat_names:\n",
    "        feat_names.append(feat_name)\n",
    "\n",
    "col_names_sep_merge = list()\n",
    "col_names_sep = list()\n",
    "index_names_sep = feat_names\n",
    "for pers_name in pers_names:\n",
    "    col_names_sep.append('D:' + pers_name + '(Rank)')\n",
    "    col_names_sep.append('D:' + pers_name + '(Corr)')\n",
    "    col_names_sep.append('P:' + pers_name + '(Rank)')\n",
    "    col_names_sep.append('P:' + pers_name + '(Corr)')\n",
    "    col_names_sep_merge.append('Rank   ')\n",
    "    col_names_sep_merge.append('Corr   ')\n",
    "    col_names_sep_merge.append('Rank   ')\n",
    "    col_names_sep_merge.append('Corr   ')\n",
    "    \n",
    "df_score_sep_merge = pd.DataFrame(index = index_names_sep, columns = col_names_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in df_score_sep_merge.columns.tolist():\n",
    "    for index_name in df_score_sep_merge.index.tolist():\n",
    "        model = col_name.split(':')[0]\n",
    "        pers_name = col_name.split(':')[1].split('(')[0]\n",
    "        categ = col_name.split(':')[1].split('(')[1][0:4]\n",
    "        if model == 'D':\n",
    "            df_score_sep_merge.loc[index_name, col_name] = df_score_old.loc[pers_name, index_name + '(' + categ + ')']\n",
    "        if model == 'P':\n",
    "            df_score_sep_merge.loc[index_name, col_name] = df_score_new.loc[pers_name, index_name + '(' + categ + ')']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_index_new = list()\n",
    "for i in df_score_sep_merge.index.tolist():\n",
    "    ls_index_new.append(df_feat.loc[i, 'Definition'] + ':' + i)\n",
    "df_score_sep_merge.columns = col_names_sep_merge\n",
    "df_score_sep_merge.index = ls_index_new\n",
    "df_score_sep_merge.to_csv('feat_rank_corr_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/ry4jr/Library/Mobile Documents/com~apple~CloudDocs/AAPEX/results')\n",
    "# Load the definition and abbreviation of featurs\n",
    "df_feat_defi = pd.read_csv('feat_def.csv')\n",
    "df_ml_input = pd.read_csv('ml_input.csv', index_col = 0)\n",
    "df_ml_input['neoNeuroticism'] = 4 - np.array(df_ml_input['neoNeuroticism'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_names_output = ['Antagonism', 'Detachment', 'Disinhibition', 'Negative Affectivity', 'Psychoticism', 'Agreeableness', 'Extraversion', 'Conscientiousness', 'Emotional Stability', 'Openness']\n",
    "pers_pairs = [['catAntagonism', 'neoAgreeableness'], ['catDetachment', 'neoExtraversion'], ['catDisinhibition', 'neoConscientiousness'], ['catNegativeAffectivity', 'neoNeuroticism'], ['catPsychoticism', 'neoOpenness']]\n",
    "df_corr = df_ml_input.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_min = 100\n",
    "norm_max = 0\n",
    "ls_feat_keep = df_feat_defi['Feature'].tolist()\n",
    "ls_dfs = list()\n",
    "for pers_pair in pers_pairs:\n",
    "    pers_cat = pers_pair[0]\n",
    "    pers_neo = pers_pair[1]\n",
    "    os.chdir('/Users/ry4jr/Library/Mobile Documents/com~apple~CloudDocs/AAPEX/results/xgb_results/')\n",
    "    df_xgb_cat_feat = pd.read_csv('xgb_' + pers_cat + '_feats_raw.csv')\n",
    "    ls_xgb_cat_dict = list()\n",
    "    for i in range(len(df_xgb_cat_feat)):\n",
    "        ls_xgb_cat_dict.append(to_dict(df_xgb_cat_feat.loc[i, 'Feats']))\n",
    "\n",
    "    df_xgb_neo_feat = pd.read_csv('xgb_' + pers_neo + '_feats_raw.csv')\n",
    "    ls_xgb_neo_dict = list()\n",
    "    for i in range(len(df_xgb_neo_feat)):\n",
    "        ls_xgb_neo_dict.append(to_dict(df_xgb_neo_feat.loc[i, 'Feats']))\n",
    "\n",
    "    os.chdir('/Users/ry4jr/Library/Mobile Documents/com~apple~CloudDocs/AAPEX/results/rf_results/')\n",
    "    df_rf_cat_feat = pd.read_csv('rf_' + pers_cat + '_feats_raw.csv')\n",
    "    ls_rf_cat_dict = list()\n",
    "    for i in range(len(df_rf_cat_feat)):\n",
    "        ls_rf_cat_dict.append(to_dict(df_rf_cat_feat.loc[i, 'Feats']))\n",
    "\n",
    "    df_rf_neo_feat = pd.read_csv('rf_' + pers_neo + '_feats_raw.csv')\n",
    "    ls_rf_neo_dict = list()\n",
    "    for i in range(len(df_rf_neo_feat)):\n",
    "        ls_rf_neo_dict.append(to_dict(df_rf_neo_feat.loc[i, 'Feats']))\n",
    "        \n",
    "    df_comm_cat_feat = keep_feat(ls_feat_keep, pers_cat, comm_feat(ls_xgb_cat_dict, ls_rf_cat_dict), df_corr)\n",
    "    df_comm_neo_feat = keep_feat(ls_feat_keep, pers_neo, comm_feat(ls_xgb_neo_dict, ls_rf_neo_dict), df_corr)\n",
    "    df_comm_feat = match_abbr(df_feat_defi, pd.merge(df_comm_cat_feat, df_comm_neo_feat, suffixes=('_cat', '_neo'), on='Feature'))\n",
    "    if np.max(df_comm_feat['Importance_RF_cat']) > norm_max:\n",
    "        norm_max = np.max(df_comm_feat['Importance_RF_cat'])\n",
    "    if np.max(df_comm_feat['Importance_RF_neo']) > norm_max:\n",
    "        norm_max = np.max(df_comm_feat['Importance_RF_neo'])\n",
    "    if np.max(df_comm_feat['Importance_XGB_cat']) > norm_max:\n",
    "        norm_max = np.max(df_comm_feat['Importance_XGB_cat'])\n",
    "    if np.max(df_comm_feat['Importance_XGB_neo']) > norm_max:\n",
    "        norm_max = np.max(df_comm_feat['Importance_XGB_neo'])\n",
    "\n",
    "    if np.min(df_comm_feat['Importance_RF_cat']) < norm_min:\n",
    "        norm_min = np.min(df_comm_feat['Importance_RF_cat'])\n",
    "    if np.min(df_comm_feat['Importance_RF_neo']) < norm_min:\n",
    "        norm_min = np.min(df_comm_feat['Importance_RF_neo'])\n",
    "    if np.min(df_comm_feat['Importance_XGB_cat']) < norm_min:\n",
    "        norm_min = np.min(df_comm_feat['Importance_XGB_cat'])\n",
    "    if np.min(df_comm_feat['Importance_XGB_neo']) < norm_min:\n",
    "        norm_min = np.min(df_comm_feat['Importance_XGB_neo'])\n",
    "        \n",
    "    ls_dfs.append(df_comm_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
